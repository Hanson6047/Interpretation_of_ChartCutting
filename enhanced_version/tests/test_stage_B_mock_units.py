#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éšæ®µBç°¡å–®æ¸¬è©¦ï¼šç›´æ¥æ¸¬è©¦LLMæè¿°ç”ŸæˆåŠŸèƒ½
"""

import sys
import os

# æ·»åŠ æ¨¡çµ„è·¯å¾‘
sys.path.append('modules/pdf_Cutting_TextReplaceImage')
sys.path.append('modules/pdf_Cutting_TextReplaceImage/enhanced_version/backend')

def test_stage_b():
    print("=== éšæ®µBæ¸¬è©¦ï¼šLLMæè¿°ç”Ÿæˆ ===")
    
    try:
        from llm_providers_sB import LLMManager, LLMRequest
        from llm_description_generator_v2_sB import LLMDescriptionGeneratorV2, DescriptionRequest
        
        print("âœ… æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
        
        # å‰µå»ºMock LLMæè¿°ç”Ÿæˆå™¨
        generator = LLMDescriptionGeneratorV2("mock")  # ä½¿ç”¨Mockï¼Œä¸éœ€è¦API
        print("âœ… Mock LLMç”Ÿæˆå™¨å»ºç«‹æˆåŠŸ")
        
        # æ¨¡æ“¬éšæ®µAçš„å®Œç¾è¼¸å‡º
        fake_stage_a_results = [
            {
                "caption": "åœ–1-1 ä¸­åœ‹çš„ç®—ç›¤",
                "type": "åœ–",
                "number": "1-1",
                "context": [
                    "ä¸­åœ‹ç®—ç›¤æ˜¯å¤ä»£é‡è¦çš„è¨ˆç®—å·¥å…·ï¼Œå…·æœ‰æ‚ ä¹…çš„æ­·å²ã€‚",
                    "ç®—ç›¤ç”±æœ¨æ¡†å’Œç®—ç çµ„æˆï¼Œåˆ†ç‚ºä¸Šä¸‹å…©æ’ï¼Œä¸Šæ’ç‚ºå¤©ç ï¼Œä¸‹æ’ç‚ºåœ°ç ã€‚",
                    "ä½¿ç”¨ç®—ç›¤å¯ä»¥é€²è¡ŒåŠ æ¸›ä¹˜é™¤ç­‰å››å‰‡é‹ç®—ï¼Œæ˜¯æ±æ–¹æ•¸å­¸æ–‡åŒ–çš„é‡è¦è±¡å¾µã€‚"
                ]
            },
            {
                "caption": "è¡¨1-1 é›»è…¦ç™¼å±•å²",
                "type": "è¡¨",
                "number": "1-1", 
                "context": [
                    "é›»è…¦ç™¼å±•å¯åˆ†ç‚ºå¹¾å€‹é‡è¦éšæ®µã€‚",
                    "å¾çœŸç©ºç®¡åˆ°é›»æ™¶é«”ï¼Œå†åˆ°ç©é«”é›»è·¯ï¼Œæ¯å€‹éšæ®µéƒ½æœ‰é‡å¤§çªç ´ã€‚",
                    "ç¾ä»£é›»è…¦çš„ç™¼å±•å¥ å®šäº†è³‡è¨Šæ™‚ä»£çš„åŸºç¤ã€‚"
                ]
            }
        ]
        
        print(f"ğŸ“ æº–å‚™æ¸¬è©¦ {len(fake_stage_a_results)} å€‹åœ–è¡¨")
        
        # é€ä¸€æ¸¬è©¦æ¯å€‹åœ–è¡¨çš„æè¿°ç”Ÿæˆ
        for i, data in enumerate(fake_stage_a_results, 1):
            print(f"\n--- æ¸¬è©¦ {i}: {data['caption']} ---")
            
            # å»ºç«‹æè¿°è«‹æ±‚
            request = DescriptionRequest(
                caption_text=data["caption"],
                caption_type=data["type"],
                caption_number=data["number"],
                related_context=data["context"],
                page_number=2
            )
            
            # ç”Ÿæˆæè¿°
            result = generator.generate_description(request)
            
            # é¡¯ç¤ºçµæœ
            print(f"æˆåŠŸ: {result.success}")
            if result.success:
                print(f"ç”Ÿæˆæè¿°: {result.generated_description[:100]}...")
                print(f"ä¿¡å¿ƒåº¦: {result.confidence_score:.2f}")
                print(f"LLMæä¾›è€…: {result.llm_provider}")
                print(f"è™•ç†æ™‚é–“: {result.processing_time:.2f}ç§’")
            else:
                print(f"å¤±æ•—åŸå› : {result.error_message}")
        
        print("\nğŸ¯ éšæ®µBæ¸¬è©¦å®Œæˆï¼")
        print("âœ… Mock LLMåŠŸèƒ½æ­£å¸¸ï¼Œå¯ä»¥ç”Ÿæˆåœ–è¡¨æè¿°")
        print("ğŸ’¡ å¦‚éœ€çœŸå¯¦æè¿°ï¼Œå¯åˆ‡æ›åˆ°OpenAIæˆ–æœ¬åœ°LLM")
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_stage_b()