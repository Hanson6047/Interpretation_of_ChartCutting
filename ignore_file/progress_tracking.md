# **PDF 圖表處理系統開發進度追蹤**

---
<details> <summary> ## 📅 **最新會議更新 (2024-08-05)**


### **新策略方向變更**
基於 0805 會議討論，**調整開發策略**：
- **優先方案**：Caption + 內文 → LM API → 圖表文字描述 → 向ㄐ
- **核心流程**：利用 PDF 內文中的圖表說明文字與正文關鍵段落，生成完整圖表描述

### **舊系統整體目標** *(保留作為參考)*
製作一個 PDF 圖表偵測與切割子系統，流程為：

1. 判斷 PDF 是否為 **Digital PDF** 或 **Scanned PDF**。
2. 根據判斷結果，分別：
   * **Digital PDF**：用 PyMuPDF 直接萃取圖表/圖片。
   * **Scanned PDF**：轉圖片後用 YOLO 偵測圖表，再切割儲存。
3. 對偵測出的圖表圖片進行**另存 (Cache)**，避免每次重新掃描。

---

## 🎯 **新系統目標 (優先實作)**

基於會議決議的**圖文結合處理流程**：

1. **自動分段**：使用 LangChain + RAG 架構切割 PDF 內文
2. **圖文配對**：尋找含有「如圖一」等關鍵字的 Chunk，與圖表 Caption 配對
3. **圖轉文字**：將 Caption + 相關內文送入 LM API，生成完整圖表描述
4. **文檔重組**：以生成的描述文字取代原本圖像資訊
5. **再向量化**：將文字化的 PDF 送入 RAG 系統進行向量化
6. **搜尋展示**：問答時同時調出圖表描述與原始圖表

</summary>
---

## 📍 **新開發規劃路徑 (基於會議決議)**

### **🎯 新階段 A：Caption 與內文關鍵字檢索**
<details> <summary>階段 A：Caption 與內文關鍵字檢索</summary>

**目標**：從 Digital PDF 中識別並擷取圖表說明文字 (Caption) 與相關內文段落。

* **要做的事：**
  * [x] 使用 PyMuPDF 或 pdfplumber 解析 PDF 文本結構
  * [x] 識別圖表 Caption（如：「圖 1.1」、「表 2.3」、「Figure 1」等模式）
  * [x] 搜尋內文中提及圖表的關鍵段落（如：「如圖一所示」、「參見圖 2.1」）
  * [x] 建立 Caption 與相關內文段落的對應關係
  * [x] 建立圖表位置與文字描述的映射結構

* **達成條件：**
 - [x] 能自動識別 PDF 中的所有圖表 Caption
 - [x] 能找到內文中提及該圖表的相關段落
 - [x] 建立圖文配對的資料結構

**狀態**: ✅ 已完成 (待測試驗證)

</details>

---

### **🎯 新階段 B：LLM API 圖表描述生成**
<details> <summary>階段 B：LLM API 圖表描述生成</summary>

**目標**：結合 Caption 與相關內文，生成完整的圖表描述文字。

* **要做的事：**
  * [ ] 設計提示詞模板，結合 Caption 與內文段落
  * [ ] 整合 OpenAI API 或其他 LLM API
  * [ ] 為每個圖表生成詳細的文字描述
  * [ ] 優化生成品質，確保描述準確且完整
  * [ ] 建立描述文字的格式化標準

* **達成條件：**
 - [ ] 能為每個識別的圖表生成高品質文字描述
 - [ ] 描述內容結合了 Caption 與相關內文的脈絡
 - [ ] 生成的描述適合 RAG 系統向量化

**狀態**: ⏳ 待開始

</details>

---

### **🎯 新階段 C：文檔重組與向量化整合**
<details> <summary>階段 C：文檔重組與向量化整合</summary>

**目標**：將生成的圖表描述整合回原始 PDF 內容，並進行向量化。

* **要做的事：**
  * [ ] 設計文檔重組策略，將圖表描述插入對應位置
  * [ ] 與現有 RAG_Helper.py 整合，支援圖文混合內容
  * [ ] 調整 Chunk 切割策略，保持圖表描述的完整性
  * [ ] 建立圖表描述與原始圖像的關聯索引
  * [ ] 測試向量化效果，確保圖表相關問題可被正確檢索

* **達成條件：**
 - [ ] 重組後的文檔能正確進行向量化
 - [ ] 圖表相關查詢能檢索到正確的描述
 - [ ] 保持與原始圖像的關聯性

**狀態**: ⏳ 待開始

</details>

---

### **🎯 新階段 D：問答展示整合**
<details> <summary>階段 D：問答展示整合</summary>

**目標**：在問答結果中同時展示圖表描述與原始圖像。

* **要做的事：**
  * [ ] 修改前端展示邏輯，支援圖文混合顯示
  * [ ] 建立圖表檔案存取機制
  * [ ] 設計使用者友善的圖表展示界面
  * [ ] 整合到現有的 main_web.py 和 index.html
  * [ ] 測試完整的問答流程

* **達成條件：**
 - [ ] 使用者詢問圖表相關問題時能看到對應圖像
 - [ ] 圖表描述與圖像同時顯示，提供完整資訊
 - [ ] 維持良好的使用者體驗

**狀態**: ⏳ 待開始

ㄒ

---

## 📋 **舊開發路徑 (保留作為備用方案)**

### **階段 1：PDF 類型判斷功能 (Digital vs Scan)**
<details> <summary>階段 1：PDF 類型判斷功能 (Digital vs Scan)</summary>

### **階段 1：PDF 類型判斷功能 (Digital vs Scan)**

**目標**：能快速判斷 PDF 是文字型 (Digital) 還是影像型 (Scanned)。

* **要做的事：**

  * [x] 用 PyMuPDF 萃取文字 (`page.get_text()`)，判斷文字頁數比例。
  * [x] 設定判斷門檻（例如：超過 80% 頁面有文字 → Digital）。
  * [x] 回傳 JSON 結果，包含：

    ```json
    {
      "type": "digital",
      "text_pages": [1, 2, 3],
      "image_pages": [4, 5]
    }
    ```

* **達成條件：**
 - [x] 能將 PDF 自動分類為 Digital 或 Scanned。
 - [x] 此結果可供下一階段自動分支處理。

狀態: ✅ 已完成

</details>

---

### **階段 2：Digital PDF 圖表切割與儲存**
<details>
  <summary>階段 2：Digital PDF 圖表切割與儲存</summary>

### **階段 2：Digital PDF 圖表切割與儲存**

**目標**：對 Digital PDF 直接萃取圖表，並另存為圖片檔。

* **要做的事：**

  * [x] 用 `PyMuPDF` 萃取 PDF 中的所有圖片 (`page.get_images()`）。
  * [x] 依頁碼及圖片索引命名檔案，例如：`chart_page2_img1.png`。
  * [x] 記錄圖片 metadata（頁碼、bbox、檔案路徑）。
  * [x] 將 metadata(中繼資料) 存入 JSON 檔或資料庫，格式：

    ```json
    {
      "page": 2,
      "bbox": [x1, y1, x2, y2],
      "file_path": "charts/chart_page2_img1.png",
      "description": null,
      "description_vector": null
    }
    ```
  * [x] 確保圖片儲存後可直接被調用（避免每次重新掃描）。

* **達成條件：**
 - [x] 可以針對 Digital PDF 一次性切割並儲存所有圖表圖片。
 - [x] 儲存結果有 JSON 索引檔，可供其他模組直接調用。

狀態: ✅ 已完成
</details>

---

### **階段 3：Scanned PDF 圖表偵測 (未來目標)**

<details>
  <summary>點擊展開/收合</summary>

**目標**：對掃描型 PDF 轉成圖片，並用 AI 偵測圖表。

* **要做的事（後續）**：

  * [ ] 用 `pdf2image` 將 PDF 每頁轉高解析 PNG。
  * [ ] 用 YOLO (PubLayNet 模型) 偵測圖表位置 (bbox)。
  * [ ] 用 OpenCV 切割出圖表，另存 PNG。
  * [ ] 將結果寫入 JSON 索引檔（同 Digital PDF 格式）。
  * [ ] （選配）可加 OCR 或 ChatGPT Vision 產生圖表描述文字。

**達成條件：**
- [x] 掃描 PDF 能自動偵測圖表並裁切。
- [x] 與 Digital PDF 有一致的 JSON metadata 格式。

狀態: ❌ 未完成
</details>

---

### **階段 4：Cache 圖片與資料管理**

<details>
  <summary>點擊展開/收合</summary>

**目標**：避免重複處理 PDF，每次可直接讀取已儲存的圖片與 JSON metadata。

* **要做的事：**

  * [ ] 設定圖表儲存目錄（如 `charts/`）。
  * [ ] 檢查 JSON metadata 是否已存在 → 若存在則跳過重新處理。
  * [ ] 提供查詢功能，能根據 PDF 名稱快速載入圖表結果。

* **達成條件：**
 * [ ]  PDF 處理結果可重複使用，不需重新掃描或偵測。
   * [ ] 提升系統效能，節省 API / GPU 資源。

狀態: ❌ 未完成
</details>

---

### **階段 5：API 化整合 (連結大系統)**

<details>
  <summary>點擊展開/收合</summary>

**目標**：將子系統封裝成 API，方便大系統調用。

* **要做的事：**

  * [ ] 用 FastAPI 實作 API：

    * `/pdf/check-type` → 判斷 PDF 類型。
    * `/pdf/digital-extract` → Digital 圖表切割與儲存。
    * `/pdf/scanned-extract` → Scanned 圖表偵測與裁切。
  * [ ] 文件化 API（Swagger UI 自動生成）。
  * [ ] 加入 API Key 認證。

* **達成條件：**
 - [ ]  大系統可用 API 呼叫子系統功能。
 - [ ]  圖表處理結果能直接整合進 Rec 系統。

狀態: ❌ 未完成
</details>

---

### **階段 2.5：LLM 圖片描述與 RAG 向量化 (未來規劃)**

<details>
  <summary>點擊展開/收合</summary>

**目標**：整合 LLM API 為圖片生成描述，並使用 RAG 技術建立語意搜尋功能。

* **要做的事：**

  * [ ] **LLM 圖片描述生成**：
    * [ ] 整合 ChatGPT Vision API 或其他 LLM 視覺模型
    * [ ] 為每張萃取的圖片生成詳細描述（圖表類型、內容、關鍵資訊）
    * [ ] 更新 metadata 中的 `description` 欄位

  * [ ] **RAG 向量化技術**：
    * [ ] 使用 sentence-transformers 或其他 embedding 模型
    * [ ] 將圖片描述文字轉換為向量
    * [ ] 儲存向量到 metadata 的 `description_vector` 欄位
    * [ ] 考慮與德育同學的向量資料庫架構整合

  * [ ] **語意搜尋功能**：
    * [ ] 實作基於描述的圖片搜尋功能
    * [ ] 支援自然語言查詢（如："尋找包含統計圖表的圖片"）
    * [ ] 返回相似度排序的搜尋結果

* **達成條件：**
 - [ ] 每張圖片都有 AI 生成的詳細描述
 - [ ] 支援語意搜尋功能，可快速找到相關圖表
 - [ ] 與整體 RAG 系統架構整合

* **技術考量：**
 - [ ] API 成本控制（LLM 調用優化）
 - [ ] 向量資料庫選擇（Chroma, Faiss, 或現有架構）
 - [ ] 批次處理大量圖片的效能優化

狀態: ❌ 未完成 (已預留欄位和方法架構)
</details>

---
## Step 6
讓 AI 把圖表歸納成一段文字，存成 .txt 或其他檔案餵給 API

## 🔍 **目前進度與下一步**

### 📋 **策略調整後的新進度**

#### ✅ **已完成的舊系統功能** *(作為備用方案保留)*
* ✅ **階段 1：PDF 類型判斷功能** - 完成
* ✅ **階段 2：Digital PDF 圖表切割與儲存** - 完成  
* 🔄 **階段 2.5：LLM 圖片描述與 RAG 向量化** - 已預留架構和欄位

#### 🎯 **新策略進度** *(基於 0805 會議決議)*
* ✅ **新階段 A：Caption 與內文關鍵字檢索** - 已完成
* ✅ **新階段 B：LM API 圖表描述生成** - 已完成  
* ✅ **新階段 C：文檔重組與向量化整合** - 已完成
* ⏳ **新階段 D：問答展示整合** - 待開始

### 🔜 **優先執行順序** 

**已完成 (2024-08-22)：**
1. ✅ **新階段 A：Caption 與內文關鍵字檢索**
   - ✅ 實作 PDF Caption 識別功能 (`caption_extractor_sA.py`)
   - ✅ 開發內文關鍵字搜尋機制
   - ✅ 建立圖文配對資料結構
   
2. ✅ **新階段 B：LM API 圖表描述生成**
   - ✅ 完成 LLM 描述生成器 (`llm_description_generator_v2_sB.py`)
   - ✅ 支援多種 LLM 提供者整合 (`llm_providers_sB.py`)
   - ✅ 實現批次描述生成與錯誤處理

3. ✅ **新階段 C：文檔重組與向量化整合**
   - ✅ 完成增強型 RAG Helper (`enhanced_rag_helper_sC.py`)
   - ✅ 實現文檔重組與圖表描述整合
   - ✅ 建立伴生索引系統 (chart_metadata.json, enhanced_faiss_index)
   - ✅ 完成測試結果統一管理功能
   - ✅ 委託現有 RAG Helper 進行向量化處理

**進行中：**
4. ⏳ **新階段 D：問答展示整合** - 準備階段
   - 📋 需準備圖片檔案供前端顯示
   - 📋 整合圖文混合檢索與展示功能

### 💡 **會議決議要點回顧**

**核心策略變更：**
- ❌ 不再直接抽取圖像進行處理
- ✅ 改為利用 Caption + 內文脈絡生成圖表描述
- ✅ 專注 Digital PDF，暫緩 Scanned PDF
- ✅ 整合現有 LangChain + RAG 架構

**預期效益：**
- 降低圖像處理複雜度
- 提升圖文關聯性
- 更好的語意理解和搜尋效果
- 保持問答時的圖片展示功能

---

---

## 📋 **階段 A-C 完成總結 (2024-08-22)**

### **🎯 主要成果**
- ✅ **完整圖表處理流程**：從 PDF Caption 識別到 LLM 描述生成
- ✅ **增強型 RAG 系統**：圖文混合文檔與向量化整合
- ✅ **模組化架構**：各階段獨立開發與測試
- ✅ **測試環境完善**：自動產生測試結果到專用資料夾

### **🔧 核心技術實現**
1. **Caption 提取技術** (`caption_extractor_sA.py`)
   - 自動識別 PDF 中的圖表標題
   - 建立圖文配對關係
   - 支援多種圖表類型 (figure, table)

2. **LLM 描述生成** (`llm_description_generator_v2_sB.py`)
   - 整合多種 LLM API 提供者
   - 批次處理與錯誤重試機制
   - Mock 模式支援離線測試

3. **增強型 RAG Helper** (`enhanced_rag_helper_sC.py`)
   - 委託現有 RAG Helper 進行向量化
   - 生成伴生索引檔案供階段D使用
   - 完整測試與檔案管理功能

### **📁 交付檔案結構**
```
C_complete_testResult/
├── chart_metadata.json      # 圖表元數據
├── enhanced_faiss_index/    # 向量索引
├── enhanced_docs/           # 增強文檔
└── test_summary.txt         # 測試摘要
```

### **🚀 階段D準備就緒**
- ✅ 所有必要的資料結構已建立
- ⚠️ **待補充**：圖片檔案供前端顯示
- 📋 **建議**：使用現有圖表切割功能或建立測試圖片資料夾

**下一步行動：協助階段D製作者完成圖文混合展示功能**
