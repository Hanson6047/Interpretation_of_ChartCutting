"""
é©—è­‰æ¸¬è©¦è…³æœ¬ - è©³ç´°æª¢æŸ¥ Caption è­˜åˆ¥æº–ç¢ºæ€§

æä¾›å¤šç¨®é©—è­‰æ–¹å¼ä¾†ç¢ºèª Caption è™•ç†çš„æ­£ç¢ºæ€§
"""

import sys
import os
from pathlib import Path

# è¨­å®š UTF-8 ç·¨ç¢¼è¼¸å‡º
if sys.platform == "win32":
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)

def extract_raw_pdf_text(pdf_path):
    """æå– PDF åŽŸå§‹æ–‡å­—ï¼Œç”¨æ–¼äººå·¥æ¯”å°"""
    import fitz
    
    text_by_page = {}
    try:
        pdf_doc = fitz.open(pdf_path)
        for page_num in range(len(pdf_doc)):
            page = pdf_doc.load_page(page_num)
            text = page.get_text()
            text_by_page[page_num + 1] = text
        pdf_doc.close()
    except Exception as e:
        print(f"âŒ æå–PDFæ–‡å­—å¤±æ•—: {e}")
    
    return text_by_page

def find_manual_captions(text_by_page):
    """æ‰‹å‹•æœå°‹ Caption æ¨¡å¼ï¼Œç”¨æ–¼å°æ¯”"""
    import re
    
    manual_captions = []
    
    # ç°¡åŒ–çš„ Caption æœå°‹æ¨¡å¼
    patterns = [
        r'åœ–\s*(\d+[\.-]\d+|\d+)[:ï¼š]\s*(.+)',
        r'è¡¨\s*(\d+[\.-]\d+|\d+)[:ï¼š]\s*(.+)', 
        r'Figure\s*(\d+[\.-]\d+|\d+)[:ï¼š.]?\s*(.+)',
        r'Table\s*(\d+[\.-]\d+|\d+)[:ï¼š.]?\s*(.+)',
    ]
    
    for page_num, text in text_by_page.items():
        lines = text.split('\n')
        for line_num, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
                
            for pattern in patterns:
                match = re.search(pattern, line, re.IGNORECASE)
                if match:
                    caption_type = "figure" if "åœ–" in pattern or "Figure" in pattern else "table"
                    manual_captions.append({
                        'page': page_num,
                        'line': line_num + 1,
                        'number': match.group(1),
                        'text': match.group(2).strip(),
                        'type': caption_type,
                        'full_line': line,
                        'context_before': lines[max(0, line_num-1):line_num],
                        'context_after': lines[line_num+1:line_num+3]
                    })
    
    return manual_captions

def find_manual_references(text_by_page):
    """æ‰‹å‹•æœå°‹å¼•ç”¨æ¨¡å¼"""
    import re
    
    manual_refs = []
    
    patterns = [
        r'å¦‚åœ–\s*(\d+[\.-]\d+|\d+)',
        r'è¦‹åœ–\s*(\d+[\.-]\d+|\d+)', 
        r'åƒè¦‹?åœ–\s*(\d+[\.-]\d+|\d+)',
        r'åœ–\s*(\d+[\.-]\d+|\d+)\s*æ‰€?ç¤º',
        r'åœ–\s*(\d+[\.-]\d+|\d+)\s*ä¸­',
        r'as shown in Figure\s*(\d+[\.-]\d+|\d+)',
        r'see Figure\s*(\d+[\.-]\d+|\d+)',
    ]
    
    for page_num, text in text_by_page.items():
        lines = text.split('\n')
        for line_num, line in enumerate(lines):
            for pattern in patterns:
                matches = re.finditer(pattern, line, re.IGNORECASE)
                for match in matches:
                    manual_refs.append({
                        'page': page_num,
                        'line': line_num + 1,
                        'number': match.group(1),
                        'full_match': match.group(0),
                        'context': line.strip(),
                        'position': match.span()
                    })
    
    return manual_refs

def compare_results(auto_pairs, manual_captions, manual_refs):
    """æ¯”è¼ƒè‡ªå‹•è­˜åˆ¥çµæžœèˆ‡æ‰‹å‹•æœå°‹çµæžœ"""
    
    print("\nðŸ” è©³ç´°é©—è­‰åˆ†æž")
    print("=" * 80)
    
    # 1. Caption æ¯”è¼ƒ
    print(f"\nðŸ“Š Caption æ¯”è¼ƒ:")
    print(f"è‡ªå‹•è­˜åˆ¥: {len(auto_pairs)} å€‹")
    print(f"æ‰‹å‹•æœå°‹: {len(manual_captions)} å€‹")
    
    # å»ºç«‹æ‰‹å‹• Caption çš„ç´¢å¼•
    manual_caption_keys = set()
    for cap in manual_captions:
        key = f"{cap['type']}_{cap['number']}"
        manual_caption_keys.add(key)
    
    # æª¢æŸ¥è‡ªå‹•è­˜åˆ¥çš„æº–ç¢ºæ€§
    auto_caption_keys = set()
    correct_matches = 0
    
    print(f"\nâœ… æ­£ç¢ºè­˜åˆ¥çš„ Caption:")
    for pair in auto_pairs:
        key = f"{pair.caption.caption_type}_{pair.caption.number}"
        auto_caption_keys.add(key)
        
        # å°‹æ‰¾åŒ¹é…çš„æ‰‹å‹• Caption
        matching_manual = None
        for manual_cap in manual_captions:
            manual_key = f"{manual_cap['type']}_{manual_cap['number']}"
            if manual_key == key:
                matching_manual = manual_cap
                break
        
        if matching_manual:
            correct_matches += 1
            print(f"  âœ“ {key}: {pair.caption.text[:50]}...")
        else:
            print(f"  âŒ {key}: å¯èƒ½æ˜¯èª¤åˆ¤ - {pair.caption.text[:50]}...")
    
    # æª¢æŸ¥éºæ¼çš„ Caption
    missed_captions = manual_caption_keys - auto_caption_keys
    if missed_captions:
        print(f"\nâŒ éºæ¼çš„ Caption:")
        for missed_key in missed_captions:
            for manual_cap in manual_captions:
                if f"{manual_cap['type']}_{manual_cap['number']}" == missed_key:
                    print(f"  âŒ {missed_key}: {manual_cap['text'][:50]}...")
                    break
    
    # 2. å¼•ç”¨æ¯”è¼ƒ
    print(f"\nðŸ“Š å¼•ç”¨æ¯”è¼ƒ:")
    auto_ref_count = sum(len(pair.contexts) for pair in auto_pairs)
    print(f"è‡ªå‹•è­˜åˆ¥: {auto_ref_count} å€‹")
    print(f"æ‰‹å‹•æœå°‹: {len(manual_refs)} å€‹")
    
    # 3. æº–ç¢ºçŽ‡è¨ˆç®—
    precision = correct_matches / len(auto_pairs) if auto_pairs else 0
    recall = correct_matches / len(manual_captions) if manual_captions else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    print(f"\nðŸ“ˆ æ€§èƒ½æŒ‡æ¨™:")
    print(f"æº–ç¢ºçŽ‡ (Precision): {precision:.3f} ({correct_matches}/{len(auto_pairs)})")
    print(f"å¬å›žçŽ‡ (Recall): {recall:.3f} ({correct_matches}/{len(manual_captions)})")
    print(f"F1 åˆ†æ•¸: {f1_score:.3f}")
    
    return {
        'precision': precision,
        'recall': recall,
        'f1_score': f1_score,
        'correct_matches': correct_matches,
        'total_auto': len(auto_pairs),
        'total_manual': len(manual_captions),
        'missed_captions': missed_captions
    }

def detailed_caption_analysis(auto_pairs, manual_captions):
    """è©³ç´°åˆ†æžæ¯å€‹ Caption"""
    
    print(f"\nðŸ”¬ è©³ç´° Caption åˆ†æž")
    print("=" * 80)
    
    print(f"\nðŸ“‹ æ‰‹å‹•æœå°‹åˆ°çš„ Caption:")
    for i, cap in enumerate(manual_captions[:10], 1):  # åªé¡¯ç¤ºå‰10å€‹
        print(f"{i:2d}. {cap['type']} {cap['number']} (é {cap['page']})")
        print(f"    å…§å®¹: {cap['text'][:80]}...")
        print(f"    å®Œæ•´è¡Œ: {cap['full_line'][:100]}...")
        print()
    
    if len(manual_captions) > 10:
        print(f"... é‚„æœ‰ {len(manual_captions) - 10} å€‹ Caption")

def interactive_validation():
    """äº’å‹•å¼é©—è­‰"""
    
    print(f"\nðŸ¤” äº’å‹•å¼é©—è­‰æ¨¡å¼")
    print("=" * 80)
    print("ç¾åœ¨å°‡é¡¯ç¤ºè‡ªå‹•è­˜åˆ¥çš„çµæžœï¼Œè«‹æ‰‹å‹•ç¢ºèªæ­£ç¢ºæ€§...")
    
    try:
        from caption_extractor import PDFCaptionContextProcessor
        
        processor = PDFCaptionContextProcessor()
        test_pdf = Path("ignore_file/test_pdf_data/sys_check_digital/è¨ˆæ¦‚ç¬¬ä¸€ç« .pdf")
        
        if not test_pdf.exists():
            print("âŒ æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨")
            return
        
        pairs = processor.process_pdf(str(test_pdf))
        
        print(f"\næ‰¾åˆ° {len(pairs)} å€‹é…å°çµæžœ")
        print("è«‹é€ä¸€ç¢ºèª (y=æ­£ç¢º, n=éŒ¯èª¤, s=è·³éŽ, q=é€€å‡º):")
        
        correct_count = 0
        total_checked = 0
        
        for i, pair in enumerate(pairs[:10], 1):  # åªæª¢æŸ¥å‰10å€‹
            print(f"\n--- é…å° {i}/{min(10, len(pairs))} ---")
            print(f"é¡žåž‹: {pair.caption.caption_type}")
            print(f"ç·¨è™Ÿ: {pair.caption.number}")
            print(f"é æ•¸: {pair.caption.page_number}")
            print(f"å…§å®¹: {pair.caption.text}")
            print(f"ä¿¡å¿ƒåº¦: {pair.pairing_confidence:.3f}")
            
            if pair.contexts:
                print("å¼•ç”¨:")
                for ctx in pair.contexts[:3]:  # æœ€å¤šé¡¯ç¤º3å€‹å¼•ç”¨
                    print(f"  - {ctx.text} (é {ctx.page_number})")
            
            while True:
                response = input("é€™å€‹çµæžœæ­£ç¢ºå—Ž? [y/n/s/q]: ").lower().strip()
                if response in ['y', 'n', 's', 'q']:
                    break
                print("è«‹è¼¸å…¥ y, n, s æˆ– q")
            
            if response == 'q':
                break
            elif response == 'y':
                correct_count += 1
                total_checked += 1
            elif response == 'n':
                total_checked += 1
            # s = è·³éŽï¼Œä¸è¨ˆå…¥çµ±è¨ˆ
        
        if total_checked > 0:
            accuracy = correct_count / total_checked
            print(f"\nðŸ“Š äººå·¥é©—è­‰çµæžœ:")
            print(f"æª¢æŸ¥æ•¸é‡: {total_checked}")
            print(f"æ­£ç¢ºæ•¸é‡: {correct_count}")
            print(f"äººå·¥æº–ç¢ºçŽ‡: {accuracy:.3f}")
        
    except Exception as e:
        print(f"âŒ äº’å‹•å¼é©—è­‰ç™¼ç”ŸéŒ¯èª¤: {e}")

def main():
    """ä¸»é©—è­‰å‡½æ•¸"""
    
    print("ðŸ” Caption è™•ç†çµæžœé©—è­‰å·¥å…·")
    print("=" * 80)
    
    test_pdf = Path("ignore_file/test_pdf_data/sys_check_digital/è¨ˆæ¦‚ç¬¬ä¸€ç« .pdf")
    
    if not test_pdf.exists():
        print("âŒ æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨")
        return
    
    # 1. æå–åŽŸå§‹æ–‡å­—
    print("ðŸ“„ æå–PDFåŽŸå§‹æ–‡å­—...")
    text_by_page = extract_raw_pdf_text(str(test_pdf))
    print(f"âœ… æå–äº† {len(text_by_page)} é æ–‡å­—")
    
    # 2. æ‰‹å‹•æœå°‹ Caption å’Œå¼•ç”¨
    print("ðŸ” æ‰‹å‹•æœå°‹ Caption...")
    manual_captions = find_manual_captions(text_by_page)
    print(f"âœ… æ‰‹å‹•æ‰¾åˆ° {len(manual_captions)} å€‹ Caption")
    
    print("ðŸ” æ‰‹å‹•æœå°‹å¼•ç”¨...")
    manual_refs = find_manual_references(text_by_page)
    print(f"âœ… æ‰‹å‹•æ‰¾åˆ° {len(manual_refs)} å€‹å¼•ç”¨")
    
    # 3. è‡ªå‹•è™•ç†
    print("ðŸ¤– åŸ·è¡Œè‡ªå‹•è™•ç†...")
    try:
        from caption_extractor import PDFCaptionContextProcessor
        processor = PDFCaptionContextProcessor()
        auto_pairs = processor.process_pdf(str(test_pdf))
        print(f"âœ… è‡ªå‹•è­˜åˆ¥ {len(auto_pairs)} å€‹é…å°çµæžœ")
    except Exception as e:
        print(f"âŒ è‡ªå‹•è™•ç†å¤±æ•—: {e}")
        return
    
    # 4. æ¯”è¼ƒçµæžœ
    metrics = compare_results(auto_pairs, manual_captions, manual_refs)
    
    # 5. è©³ç´°åˆ†æž
    detailed_caption_analysis(auto_pairs, manual_captions)
    
    # 6. äº’å‹•å¼é©—è­‰ (å¯é¸)
    print(f"\nâ“ æ˜¯å¦é€²è¡Œäº’å‹•å¼é©—è­‰? (y/n): ", end="")
    try:
        if input().lower().strip() == 'y':
            interactive_validation()
    except (EOFError, KeyboardInterrupt):
        print("\nç¨‹å¼çµæŸ")
    
    # 7. ç¸½çµ
    print(f"\nðŸŽ¯ é©—è­‰ç¸½çµ")
    print("=" * 80)
    if metrics['f1_score'] >= 0.8:
        print("âœ… è­˜åˆ¥å“è³ª: å„ªç§€")
    elif metrics['f1_score'] >= 0.6:
        print("âš ï¸ è­˜åˆ¥å“è³ª: è‰¯å¥½ï¼Œå¯é€²è¡ŒéšŽæ®µB")
    else:
        print("âŒ è­˜åˆ¥å“è³ª: éœ€è¦æ”¹é€²")
    
    print(f"F1åˆ†æ•¸: {metrics['f1_score']:.3f}")
    print(f"å»ºè­°: {'å¯ä»¥é€²å…¥éšŽæ®µB' if metrics['f1_score'] >= 0.5 else 'å»ºè­°å…ˆå„ªåŒ–éšŽæ®µA'}")

if __name__ == "__main__":
    main()